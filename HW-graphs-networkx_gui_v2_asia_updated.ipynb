{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:09:12.336902Z",
     "start_time": "2018-12-22T19:09:12.331915Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import collections\n",
    "from tqdm import tqdm, tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [RQ1]\n",
    "**Creating Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:07:35.019760Z",
     "start_time": "2018-12-22T19:07:35.015772Z"
    }
   },
   "outputs": [],
   "source": [
    "DG = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:07:49.877732Z",
     "start_time": "2018-12-22T19:07:35.580473Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/Asia/\"\n",
    "\n",
    "# i.e. our_edges = {node1:[node2,node4,node5], ..., 1:[2, 3, 5], 2:[5], 3:[6] ....}\n",
    "# our_edges = defaultdict(list)\n",
    "\n",
    "with open(path + \"wiki-topcats-reduced.txt\", \"r\") as f:\n",
    "    #create graph\n",
    "    for line in f.readlines():\n",
    "        article1, article2 = line.split()\n",
    "        DG.add_weighted_edges_from([(int(article1), int(article2), 1)])\n",
    "#         our_edges[int(article1)].append(int(article2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:07:50.310955Z",
     "start_time": "2018-12-22T19:07:49.923988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is graph directed?  True \n",
      "\n",
      "Since the neighbors of 52nd node are: 401135 1069112 1163551 ,52nd node is not neighbor for 1069112nd node which has connection with 1060396 1061304 1062611 1066969 1069008 1069113 1069258 1069275 1656982  nodes. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Is graph directed?\n",
    "print(\"Is graph directed? \", nx.is_directed(DG), \"\\n\") # check whether graph is directed or not\n",
    "\n",
    "# example;\n",
    "print(\"Since the neighbors of 52nd node are:\", *list(DG.neighbors(52)),\n",
    "      \",52nd node is not neighbor for 1069112nd node which has connection with\", *list(DG.neighbors(1069112)),\" nodes. \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes: 461193 \n",
      "\n",
      "The number of edges: 2645247\n"
     ]
    }
   ],
   "source": [
    "# The number of nodes\n",
    "nodes_num = DG.number_of_nodes()\n",
    "print(\"The number of nodes:\", nodes_num, \"\\n\") # also len(DG) works\n",
    "\n",
    "# The number of edges\n",
    "edges_num = DG.number_of_edges()\n",
    "print(\"The number of edges:\", edges_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph density**\n",
    "In mathematics, a dense graph is a graph in which the number of edges is close to the maximal number of edges. The opposite, a graph with only a few edges, is a sparse graph. The distinction between sparse and dense graphs is rather vague, and depends on the context.\n",
    "\n",
    "For directed graphs, the graph density is defined as:\n",
    "$$D = \\frac{|E|}{|V|(|V|-1)}$$\n",
    "\n",
    "where E is the number of edges and V is the number of vertices in the graph. The maximum number of edges for an directed graph is $|V|(|V|-1).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:07:50.364809Z",
     "start_time": "2018-12-22T19:07:50.355833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.590986317548208e-08\n"
     ]
    }
   ],
   "source": [
    "density = nodes_num / (edges_num*(edges_num-1))\n",
    "print(density);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [RQ2] \n",
    "Given a category $C_0 = \\{article_1, article_2, \\dots \\}$ as input we want to rank all of the nodes in V according to the block-ranking, where the blocks are represented by the categories:\n",
    "$$block_{RANKING} =\\begin{bmatrix} C_0 \\\\ C_1 \\\\ \\dots \\\\ C_c\\\\ \\end{bmatrix}$$\n",
    "\n",
    "Each category  corresponds to a list of nodes.\n",
    "\n",
    "The first category of the rank, $C_0$, always corresponds to the input category. The order of the remaining categories is given by:\n",
    "\n",
    "$$distance(C_0, C_i) = median(ShortestPath(C_0, C_i))$$\n",
    "\n",
    "The lower is the distance from $C_0$, the higher is the $C_i$ position in the rank. $ShortestPath(C_0, C_i)$ is the set of all the possible shortest paths between the nodes of $C_0$ and $C_i$. Moreover, the length of a path is given by the sum of the weights of the edges it is composed by."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the file with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:08:00.923314Z",
     "start_time": "2018-12-22T19:07:58.812023Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(path + \"wiki-topcats-categories.txt\", \"r\") as f2:\n",
    "    categories = {} # {category0 : [article1, article2, ...], ...., 5: [23, 45, 6]}\n",
    "    categories_names = {} # {category_name : index, ...}\n",
    "    for cat_indx, line in enumerate(f2.readlines()):\n",
    "        line_content = line.split(\";\")\n",
    "        categories[cat_indx] = list(map(int, line_content[1].split()))\n",
    "        categories_names[line_content[0].split(\":\")[1]] = cat_indx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide the name of category $C0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, choose the name of category: \n",
      "\n",
      "Fellows_of_the_Royal_Society\n",
      "The index of selected category:  10839\n"
     ]
    }
   ],
   "source": [
    "C0_name = input(\"Please, choose the name of category: \\n\\n\")\n",
    "C0_idx = categories_names[C0_name]\n",
    "print(\"The index of selected category: \", C0_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering categories which exist in our reduced graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:08:07.426599Z",
     "start_time": "2018-12-22T19:08:06.181884Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_selected_category_indx = []\n",
    "# filtering categories with nodes more than 3500\n",
    "for i in range(len(categories)):\n",
    "    if len(categories[i]) > 3500:\n",
    "        tmp_selected_category_indx.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing categories for further analysis.\n",
    "As one article might belong to a single category or multiple ones.\n",
    "If the article belongs to the input categor it belongs to that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:08:07.426599Z",
     "start_time": "2018-12-22T19:08:06.181884Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_categories_nodes = [] # nodes grouped per category -- without C0 category\n",
    "categories_nodes = set() # all nodes together -- without C0 category\n",
    "\n",
    "# chose the category C0 with nodes only included in the DG graph:\n",
    "C0 = set(categories[C0_idx]).intersection(DG.nodes)\n",
    "\n",
    "final_selected_category_indx = []\n",
    "# chose categories with nodes only included in the DG graph:\n",
    "for idx in tmp_selected_category_indx[1:]:\n",
    "    tmp_categ = set(categories[idx]).intersection(DG.nodes)\n",
    "    # if C_i contains different nodes than C0:\n",
    "    C_i = tmp_categ - C0\n",
    "    if len(C_i) != 0 and len(C_i) < 100000:\n",
    "        final_selected_category_indx.append(idx)\n",
    "        grouped_categories_nodes.append(C_i)\n",
    "        categories_nodes = categories_nodes.union(C_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm for searching the Shortest path  -  BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T12:42:24.579009Z",
     "start_time": "2018-12-22T12:42:24.571032Z"
    }
   },
   "outputs": [],
   "source": [
    "def bfs_shortest_path(graph, start, categories_nodes):\n",
    "    visited_dict = defaultdict(lambda:[False])\n",
    "    queue = [start]\n",
    "    visited_dict[start] = 0\n",
    "    \n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        distance = visited_dict[node]\n",
    "        try:\n",
    "            for neighbour in graph.neighbors(node):\n",
    "                if visited_dict[neighbour]==[False]:\n",
    "                    visited_dict[neighbour] = distance + 1\n",
    "                    queue.append(neighbour)\n",
    "        except KeyError: pass\n",
    "    return {node:visited_dict[node] for node in categories_nodes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article_distances = {}\n",
    "counter = 0\n",
    "\n",
    "for idx, node in enumerate(C0):\n",
    "    article_distances[node] = bfs_shortest_path(DG, node, categories_nodes)\n",
    "    if (idx+1)%100==0:\n",
    "        with open('distance_' + str(counter) + '.pkl', 'wb') as file:\n",
    "            pickle.dump(article_distances, file, pickle.HIGHEST_PROTOCOL)\n",
    "        article_distances = dict(); counter+=1\n",
    "\n",
    "with open('distance_' + str(counter) + '.pkl', 'wb') as file:\n",
    "    pickle.dump(article_distances, file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping categories with distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:08:50.568075Z",
     "start_time": "2018-12-22T19:08:50.564090Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/guilh/Desktop/ADM/HW5/distances_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:31:27.687878Z",
     "start_time": "2018-12-22T19:14:51.799346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb360e0f6c294ab0a1012ef581ce4db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j in tnrange(35):\n",
    "    \n",
    "    with open(path + 'distance_' + str(j) + '.pkl', 'rb') as file:\n",
    "        distance_dict = pickle.load(file)\n",
    "    \n",
    "    distances_categories = []\n",
    "    \n",
    "    #for each category selected previously excluding C0\n",
    "    for i in final_selected_category_indx:\n",
    "        distances = []\n",
    "        #for each node in this selected category underanalysis\n",
    "        for node in categories[i]:\n",
    "            #for the starting node of C0 into our distance file\n",
    "            for starting_node in distance_dict:\n",
    "                #try to find the distances from C0 node to the node inside the category under analysis\n",
    "                try:\n",
    "                    d = distance_dict[starting_node][node]\n",
    "                    if d != [False]:\n",
    "                        distances.append(d)\n",
    "                        #if distance is false append 9999\n",
    "                    else: distances.append(9999)\n",
    "                        \n",
    "                except: pass\n",
    "        #append the results of distances to this category\n",
    "        distances_categories.append(distances)\n",
    "    \n",
    "    \n",
    "    #save this distances and after each iteration we concatenate to it\n",
    "    if j == 0:\n",
    "        distances_concatenated = np.array([distances_categories])\n",
    "    else:\n",
    "        np.concatenate((distances_concatenated, np.array([distances_categories])), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the median and making a dictionary to the category index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:40:51.737334Z",
     "start_time": "2018-12-22T19:40:50.237820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf95d648ac24cefa991094ac7a1e30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "medians_dict = {}\n",
    "for i in tnrange(len(final_selected_category_indx)):\n",
    "    medians_dict[final_selected_category_indx[i]] = np.median(distances_concatenated[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T19:41:25.124657Z",
     "start_time": "2018-12-22T19:41:25.109636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{869: 8.0,\n",
       " 876: 12.0,\n",
       " 898: 9999.0,\n",
       " 900: 9999.0,\n",
       " 949: 9999.0,\n",
       " 1881: 9999.0,\n",
       " 2791: 8.0,\n",
       " 4160: 9.0,\n",
       " 5619: 6.0,\n",
       " 6067: 7.0,\n",
       " 6795: 9999.0,\n",
       " 6893: 10.0,\n",
       " 7628: 8.0,\n",
       " 7889: 7.0,\n",
       " 8732: 9999.0,\n",
       " 8733: 9999.0,\n",
       " 10062: 7.0,\n",
       " 10139: 6.0,\n",
       " 10251: 6.0,\n",
       " 10555: 6.0,\n",
       " 10564: 6.0,\n",
       " 11640: 6.0,\n",
       " 11641: 6.0,\n",
       " 11648: 6.0,\n",
       " 11649: 6.0,\n",
       " 11992: 7.0,\n",
       " 12631: 6.0,\n",
       " 12941: 9999.0,\n",
       " 12966: 8.0,\n",
       " 13838: 6.0,\n",
       " 13996: 8.0,\n",
       " 16956: 8.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Ranging Algorithm - Step 1 , 2 , 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genergic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_weighted_edges_from([('A','B',1)])\n",
    "G.add_weighted_edges_from([('A','C',1)])\n",
    "G.add_weighted_edges_from([('A','D',0)])\n",
    "G.add_weighted_edges_from([('B','C',1)])\n",
    "G.add_weighted_edges_from([('B','E',1)])\n",
    "G.add_weighted_edges_from([('D','B',100)]) #its weight isnt important\n",
    "G.add_weighted_edges_from([('D','E',1)])\n",
    "G.add_weighted_edges_from([('D','G',1)])\n",
    "G.add_weighted_edges_from([('E','C',100)]) #its weight isnt important\n",
    "G.add_weighted_edges_from([('E','G',2)])\n",
    "G.add_weighted_edges_from([('F','C',100)]) #its weight isnt important\n",
    "G.add_weighted_edges_from([('G','F',1)])\n",
    "G.add_weighted_edges_from([('H','G',1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {1: ['A','B','C'], 2: ['D','E'], 3: ['F','G','H']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0 = categories[1]\n",
    "induced_graph = G.subgraph(C0) # create sub graph for only category zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C0_sum_weights_inedges(induced_graph):\n",
    "    # Iterate to get sum of weights of in-edges\n",
    "    all_weights = {} # it will look like {node1:sum_of_weights, node2:sum_of_weights, ...}\n",
    "    for (node1,node2,data) in induced_graph.edges(data=True):\n",
    "        if node2 not in all_weights.keys(): # we consider node2 because we're checking how many \"incoming\" neighboors\n",
    "            all_weights[node2] = data['weight'] # if node2 doesn't exist in all_weights, just add initial weight\n",
    "        else:\n",
    "            all_weights[node2] += data['weight'] # if node2 already exists in all_weights, add weight up like cumulate weight\n",
    "    \n",
    "    # if there is no incoming neigboors, detect these nodes and give their values as zero\n",
    "    for zero_node in list(set(induced_graph.nodes()) - set(all_weights.keys())):\n",
    "        all_weights[zero_node]=0\n",
    "        \n",
    "    all_weights = sorted(all_weights.items(), key=lambda kv: kv[1], reverse=True) # sort with descending order by values in dictionary \n",
    "\n",
    "    return all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0_score = C0_sum_weights_inedges(induced_graph)\n",
    "C0_score # score for just category 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = categories[2] \n",
    "sub_graph = G.subgraph(list(C0) + C1) # create sub graph for only category 0 and category 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_score = {} # it is the score for only category 1\n",
    "\n",
    "\"\"\" apply same steps as step 1. The only difference is we use C0 as induced category. That means Since C0 is the first \n",
    "    ordered category, we need to take into account if there incoming arrows(directions) from catefory 0. We have to count\n",
    "    also. So thats why we create sub graph with C0 and C1\"\"\"\n",
    "for (node1,node2,data) in sub_graph.edges(data=True):\n",
    "    if node2 in C1:\n",
    "        if node2 not in C1_score.keys():\n",
    "            C1_score[node2] = data['weight']\n",
    "        else:\n",
    "            C1_score[node2] += data['weight']\n",
    "            \n",
    "for zero_node in list(set(C1) - set(C1_score.keys())):\n",
    "    C1_score[zero_node]=0\n",
    "        \n",
    "C1_score = sorted(C1_score.items(), key=lambda kv: kv[1], reverse=True) # sort by values\n",
    "C1_score # for only category 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(DG, ordered_category_indx, C0_score):\n",
    "    C_0 = list(categories[ordered_category_indx[0]])\n",
    "    cum_nodes_list = C_0 # cumulative nodes list\n",
    "    all_weights = {}\n",
    "    all_weights.update(C0_score) # append induced category rank and sum of weights\n",
    "\n",
    "    for cat_idx in ordered_category_indx:\n",
    "        C_i = list(categories[cat_idx])\n",
    "        cum_nodes_list = cum_nodes_list + C_i # we need to build sub graph cumulatively\n",
    "        sub_graph = DG.subgraph(cum_nodes_list)\n",
    "        \n",
    "        cat_weights = {} # weights for only category C_i\n",
    "        for (node1,node2,data) in sub_graph.edges(data=True):\n",
    "            if node2 in C_i:\n",
    "                if node2 not in cat_weights.keys():\n",
    "                    cat_weights[node2] = data['weight']\n",
    "                else:\n",
    "                    cat_weights[node2] += data['weight']\n",
    "    \n",
    "        for zero_node in list(set(C_i) - set(cat_weights.keys())):\n",
    "            cat_weights[zero_node] = 0\n",
    "            \n",
    "        cat_weights = sorted(cat_weights.items(), key=lambda kv: kv[1], reverse=True) # before adding to all_weights sort weights just inside the category C_i\n",
    "        all_weights.update(cat_weights) # add cat_weights to all_weights\n",
    "    \n",
    "    return all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "ordered_category_indx = [1,2,3] # in hw example order: C0,C1,C2\n",
    "nodes_rank = score(G, ordered_category_indx, C0_score)\n",
    "print(\"nodes rank and their weights:\", nodes_rank)\n",
    "print(\"nodes rank:\", nodes_rank.keys())\n",
    "\n",
    "delta = time.time() - start_time\n",
    "print(\"running time:\", delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
